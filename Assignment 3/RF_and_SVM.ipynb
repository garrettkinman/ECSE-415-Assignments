{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5ab9a0a81ed0579ddd6b99cc4068a883f83e53a2048741e0a735f2f957c962ef"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "source": [
    "# Assignment 3\n",
    "\n",
    "## Image Classification Using RF and SVM\n",
    "\n",
    "1. Resize the train/test images to 64 × 64 and compute HoG features using cells of 8×8 pixels, blocks of 4×4 cells and 4 bins. This should yeild a feature vector of size 1600 per image.\n",
    "2. Fit a non-linear SVM classifier (use RBF kernel with gamma=‘auto’ and C=1) on the features and the class labels of the training images. \n",
    "3. Predict labels of the test images by feeding the test features to the trained classifier and calculate classification accuracy.\n",
    "4. Tune values of hyperparameters ‘gamma’ and ‘C’ to achieve test accuracy greater than 25%.\n",
    "5. Fit a Random Forest(RF) classifier (set n estimators=10, max depth=5 and criterion=‘entropy’) on the features and the class labels of the training images.\n",
    "6. Predict labels of the test images by feeding the test features to the trained classifier and calculate classification accuracy.\n",
    "7. Tune values of hyperparameters ‘n estimators’ and ‘max depth’ to achieve test accuracy greater than 25%. \n",
    "8. Compare results of SVM and RF classifiers. Which one provides better results? Experiment training both classifiers with a range of random stats and measure classification accuracy of the test set. Which classifier is more stable or robust to the change in random state? "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_images\n<class 'numpy.ndarray'>\n[[[ 49  48  46 ...  65  56  50]\n  [ 42  41  39 ... 110 111 111]\n  [115 114 113 ... 167 166 165]\n  ...\n  [ 91  88  87 ...  47  52  61]\n  [ 69  73  74 ...  81  78  72]\n  [ 65  63  65 ... 178 179 178]]\n\n [[ 64  62  59 ...  76  73  72]\n  [ 68  68  69 ...  81  80  79]\n  [ 80  81  83 ...  72  72  72]\n  ...\n  [ 70  70  69 ...  98  98  98]\n  [ 94  95  96 ...  83  82  81]\n  [ 87  90  89 ...  91  91  92]]\n\n [[ 10  10  11 ...  87  87  87]\n  [ 86  86  85 ... 184 184 184]\n  [184 184 184 ... 205 205 206]\n  ...\n  [ 78  83  86 ...  54  54  55]\n  [ 55  55  56 ...  22  21  21]\n  [ 21  21  21 ...  19  21  22]]\n\n ...\n\n [[ 18  18  18 ...  39  43  45]\n  [ 46  45  44 ...  36  33  30]\n  [ 52  53  45 ... 153 151 147]\n  ...\n  [ 22  23  23 ...  31  31  32]\n  [ 29  31  34 ... 122 115  95]\n  [ 82 104  94 ...  36  37  38]]\n\n [[ 40  40  42 ...  69  61  54]\n  [ 46  42  37 ...  36  29  24]\n  [ 20  19  17 ...  38  39  39]\n  ...\n  [ 17  17  18 ...  42  41  39]\n  [ 37  35  33 ...  64  61  57]\n  [ 54  52  49 ...  66  66  65]]\n\n [[103 103 103 ... 105 110 113]\n  [127 128 126 ...  76  77  78]\n  [ 80  81  82 ...  91  89  88]\n  ...\n  [ 86  88  93 ... 186 185 184]\n  [184 182 180 ... 173 174 176]\n  [191 194 198 ... 125 129 132]]]\ntrain_labels\n<class 'numpy.ndarray'>\n[0 0 0 ... 8 8 8]\ntest_images\n<class 'numpy.ndarray'>\n[[[ 49  47  45 ... 143 145 147]\n  [149 151 154 ... 107 105 102]\n  [105 103  99 ... 104 106 106]\n  ...\n  [ 61  64  67 ...  88  85  84]\n  [ 82  82  81 ... 118 115 114]\n  [110 108 105 ... 101  93  87]]\n\n [[ 39  39  39 ...  91  91  91]\n  [ 89  88  88 ...  71  70  69]\n  [ 70  71  71 ...  91  91  91]\n  ...\n  [ 84  84  84 ...  68  68  67]\n  [ 68  69  70 ...  62  62  62]\n  [ 60  59  58 ...  48  48  49]]\n\n [[ 48  48  48 ... 138 136 132]\n  [133 136 140 ...  91  90  90]\n  [ 90  91  91 ...  45  47  48]\n  ...\n  [ 62  61  61 ...  58  53  49]\n  [ 47  46  45 ...  81  80  80]\n  [ 85  84  84 ... 100 102 105]]\n\n ...\n\n [[ 68  70  72 ...  27  27  28]\n  [ 30  29  29 ... 108  98  92]\n  [ 91  94  97 ...  49  49  48]\n  ...\n  [ 35  35  35 ...  33  33  33]\n  [ 33  32  31 ...  84  73  73]\n  [ 66  64  62 ...  62  62  62]]\n\n [[ 50  48  49 ...  71  71  73]\n  [ 80  96 133 ... 214 210 205]\n  [200 181 168 ...  94  89  88]\n  ...\n  [ 27  27  28 ... 167 176 175]\n  [174 170 167 ... 180 178 185]\n  [190 192 193 ... 139 146 152]]\n\n [[ 80  81  81 ... 101  95 100]\n  [ 96 100 106 ...  92  90  93]\n  [101 100 100 ...  93  91  90]\n  ...\n  [147 146 146 ... 139 157 172]\n  [153 120  99 ...  77  83  90]\n  [ 95  95  95 ...  35  35  35]]]\ntest_labels\n<class 'numpy.ndarray'>\n[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3\n 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 7 7 7 7\n 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "# load in the dataset\n",
    "flower_subset = np.load(\"flower_subset.npz\")\n",
    "for file in flower_subset.files:\n",
    "    print(file)\n",
    "    print(type(flower_subset[file]))\n",
    "    print(flower_subset[file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign meaningful names to each set in the dataset\n",
    "train_images = flower_subset[\"train_images\"]\n",
    "train_labels = flower_subset[\"train_labels\"]\n",
    "test_images = flower_subset[\"test_images\"]\n",
    "test_labels = flower_subset[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_single_image(img, name):\n",
    "    \"\"\"Display a single image nicely.\"\"\"\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.subplot(111), plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(name), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_resolution(img):\n",
    "    return cv2.resize(img, dsize=(0,0), fx=0.5, fy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize to 64x64\n",
    "train_images = np.array(list(map(half_resolution, train_images)))\n",
    "test_images = np.array(list(map(half_resolution, test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create HoG Object\n",
    "# winSize is the size of the image cropped to multiple of the cell size\n",
    "# all arguments should be given in terms of number of pixels\n",
    "hog = cv2.HOGDescriptor(_winSize=(img_size[1] // cell_size[1] * cell_size[1],\n",
    "                                  img_size[0] // cell_size[0] * cell_size[0]),\n",
    "                        _blockSize=(block_size[1] * cell_size[1],\n",
    "                                    block_size[0] * cell_size[0]),\n",
    "                        _blockStride=(cell_size[1], cell_size[0]),\n",
    "                        _cellSize=(cell_size[1], cell_size[0]),\n",
    "                        _nbins=nbins)"
   ]
  }
 ]
}